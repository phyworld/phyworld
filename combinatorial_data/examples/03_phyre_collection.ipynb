{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PHYRE\n",
    "\n",
    "PHYRE consists of an environment, a two-dimensional world with Newtonian physics, and a set of tasks.\n",
    "Each task consists of an initial scene with some geometric bodies and a goal condition that should be satisified.\n",
    "An agent can introduce one or two extra objects into a scene. Once done, the agent request of sumulation of scene.\n",
    "The task is considered to be **solved**, if after the simulation the goal condition is satisfied.\n",
    "\n",
    "The image below shows three different tasks (on the left) and result of simulation with a ball introduced into the scene. Note that in the current version of the dataset all tasks have the same goal: a pair of colored object (blue, green, or purple) should touch each other.\n",
    "\n",
    "\n",
    "This notebook shows how to use the ```phyre``` API to interact with the environment and tasks and how to train a simple random agent.\n",
    "\n",
    "![PHYRE tasks](../imgs/task_example.png \"PHYRE tasks and simulation example\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this in colab\n",
    "You can open and play with this notebook in colab. \n",
    "<a href=\"https://colab.research.google.com/github/facebookresearch/phyre/blob/master/examples/01_phyre_intro.ipynb\" target=\"_parent\">Open In Colab</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install phyre and auxiliary packages.\n",
    "# !pip install phyre matplotlib tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "import phyre.loader\n",
    "all_tasks = phyre.loader.load_compiled_task_dict()\n",
    "print(len(all_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "# import torch\n",
    "import phyre\n",
    "from phyre.vis import WAD_COLORS\n",
    "\n",
    "random.seed(0)\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# WAD_COLORS_TORCH = torch.tensor(WAD_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to PHYRE simulator\n",
    "\n",
    "\n",
    "As described in the [PHYRE paper](https://arxiv.org/abs/1908.05656), the dataset consists consists of two groups of tasks referred to as **tiers**.\n",
    "Currently we have two tiers: `ball` and `two_balls`. Tasks in the former tier are guaranteed to be solvable with a single ball, i.e., a goal condition could be satisfied at the end of simulation if a ball of right size is introduced at a right location. Naturally, tasks in the latter tier require two balls.\n",
    "\n",
    "Within each tier tasks are grouped in **task templates**. Each template consists of 100 conceptually similar modifications. The image below shows some examples of tasks from different templates and from the same template.\n",
    "\n",
    "![PHYRE tasks](../imgs/cross_within.png \"PHYRE tasks and templates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval setups\n",
    "\n",
    "We can measure two types of generalization: within template and cross template.\n",
    "This could be done for both tiers resulting in four **eval setups**.\n",
    "Each eval setup defines which tasks to use for training, validation and testing. One can access the list of eval setups using `phyre.MAIN_EVAL_SETUPS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball\n",
      "200\n",
      "200\n",
      "two_balls\n",
      "300\n",
      "300\n",
      "No duplicate task IDs.\n"
     ]
    }
   ],
   "source": [
    "eval_setups = ['ball_cross_template', 'two_balls_cross_template']\n",
    "all_tasks_dict = {}\n",
    "all_tiers = []\n",
    "all_tasks_list = []\n",
    "for eval_setup in eval_setups:\n",
    "    train_tasks, dev_tasks, test_tasks = phyre.get_fold(eval_setup, 0)\n",
    "    tasks = train_tasks + dev_tasks + test_tasks\n",
    "    # if True:\n",
    "    #     tasks = random.sample(tasks, 50)\n",
    "    action_tier = phyre.eval_setup_to_action_tier(eval_setup)\n",
    "    all_tiers += [action_tier] * len(tasks)\n",
    "    # simulator = phyre.initialize_simulator(tasks, action_tier)  \n",
    "    all_tasks_dict[eval_setup] = {\n",
    "        'eval_setup': eval_setup,\n",
    "        'tasks': tasks,\n",
    "        'action_tier': action_tier,\n",
    "        # 'simulator': simulator,\n",
    "    }\n",
    "    print(action_tier)\n",
    "\n",
    "    all_tasks_list += tasks\n",
    "\n",
    "    print(len(all_tasks_list))\n",
    "    print(len(all_tiers))\n",
    "    \n",
    "# Check for duplicate task IDs\n",
    "unique_task_ids = set(all_tasks_list)\n",
    "if len(unique_task_ids) < len(all_tasks_list):\n",
    "    print(f\"There are {len(all_tasks_list) - len(unique_task_ids)} duplicate task IDs.\")\n",
    "else:\n",
    "    print(\"No duplicate task IDs.\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['00000', '00100', '10000']\n"
     ]
    }
   ],
   "source": [
    "template_dict = {}\n",
    "for task in all_tasks_list:\n",
    "    template_id, instance_id = task.split(':')\n",
    "    if template_id not in template_dict:\n",
    "        template_dict[template_id] = []\n",
    "    template_dict[template_id].append(instance_id)\n",
    "\n",
    "print(len(template_dict))\n",
    "print(sorted(list(template_dict.keys())))\n",
    "# for t in template_dict.values():\n",
    "#     print(len(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any type of generalization we can build multiple splits intro train, dev, and test. Moreover, different splits will have different complexity. Due to that reason we recommend to use 10 folds to report results (see paper for details). Here, we will a single fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000:000', '00000:001', '00000:002', '00000:003', '00000:004', '00000:005', '00000:006', '00000:007', '00000:008', '00000:009', '00000:010', '00000:011', '00000:012', '00000:013', '00000:014', '00000:015', '00000:016', '00000:017', '00000:018', '00000:019']\n",
      "['10000:080', '10000:081', '10000:082', '10000:083', '10000:084', '10000:085', '10000:086', '10000:087', '10000:088', '10000:089', '10000:090', '10000:091', '10000:092', '10000:093', '10000:094', '10000:095', '10000:096', '10000:097', '10000:098', '10000:099']\n"
     ]
    }
   ],
   "source": [
    "all_tasks_list.sort()\n",
    "print(all_tasks_list[:20])\n",
    "print(all_tasks_list[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an action tier and a set of tasks, we can build a simulator using `phyre.initialize_simulator`. For simplicity, we'll use the first 50 items from the dev split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = phyre.initialize_simulator(['10000:080'], action_tier='ball')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial vectorized objects\n",
    "\n",
    "In addition to the pixelized initial scenes, one can also get access to a vectorized state of each scene object in it's initial posiition. Each task is represented as a FeaturizedObjects, which contains features represented as a 1 x (NUM_SCENE_OBJECTS + TASK_TIER_NUM_USER_INPUTS) x 14 np.ndarray. The features of the object, in order are:\n",
    "\n",
    "\n",
    "  0. x in pixels of center of mass divided by SCENE_WIDTH\n",
    "  1. y in pixels of center of mass divided by SCENE_HEIGHT\n",
    "  2. angle of the object between 0 and 2pi divided by 2pi\n",
    "  3. diameter in pixels of object divided by SCENE_WIDTH\n",
    "  4. \\- 8. One hot encoding of the object shape, according to order: ball, bar, jar, standing sticks\n",
    "  8. \\- 14. One hot encoding of object color, according to order: red, green, blue, purple, gray, black\n",
    "  \n",
    "As the scene is vectorized into prior to user input, the rows represent only scene objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation\n",
    "\n",
    "The action space is always a unit cube, but the dimension depends on the action tier. For the ball tier, the dimensionality of the action space is 3, corresponding to the (x,y) position of the ball and its radius r. For two ball tiers the dimension is 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the action space: 3\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of the action space:', simulator.action_space_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the simulator to sample a fixed set of random actions from the action space using `build_discrete_action_space`. The function samples actions uniformly from the action cube skipping invalid ones. The set is guaranteed to be deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random action: [4.17022005e-01 7.20324493e-01 1.14374817e-04]\n"
     ]
    }
   ],
   "source": [
    "actions = simulator.build_discrete_action_space(max_actions=100)\n",
    "print('A random action:', actions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an action, we can use the simulator to simulate it. Let's simulate it on the first task instance in our dataset. The simulator returns a Simulation object containing, **status** of the simulation (`phyre.SimulationStatus`), intermediate observations, and information about the object states in a FeaturizedObjects object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_index = 0  # The simulator takes an index into simulator.task_ids.\n",
    "action = random.choice(actions)\n",
    "# Set need_images=False and need_featurized_objects=False to speed up simulation, when only statuses are needed.\n",
    "# TIME = FRAMES / FPS = k / (STRIDE * FPS)\n",
    "fps = 5\n",
    "STRIDE = int(100 / fps) #keep  STRIDE=20\n",
    "simulation = simulator.simulate_action(task_index, action, need_images=True, need_featurized_objects=True, stride=STRIDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first peice of information stored in the `simulation` is the status of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three statuses could be returned.\n",
    "print('Action solves task:', phyre.SimulationStatus.SOLVED)\n",
    "print('Action does not solve task:', phyre.SimulationStatus.NOT_SOLVED)\n",
    "print('Action is an invalid input on task (e.g., occludes a task object):',\n",
    "      phyre.SimulationStatus.INVALID_INPUT)\n",
    "# May call is_* methods on the status to check the status.\n",
    "print()\n",
    "print('Result of taking action', action, 'on task', tasks[task_index], 'is:',\n",
    "      simulation.status)\n",
    "print('Does', action, 'solve task', tasks[task_index], '?', simulation.status.is_solved())\n",
    "print('Is', action, 'an invalid action on task', tasks[task_index], '?',\n",
    "      simulation.status.is_invalid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb Cell 23\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msubplots\u001b[39;00m \u001b[39mimport\u001b[39;00m make_subplots\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objects\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgo\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/magic/yueyang/phyre/examples/03_phyre_collection.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "def normalize_probabilities(p1, p2, p3):\n",
    "    \"\"\"Normalize the probabilities to sum to 1.\"\"\"\n",
    "    total = p1 + p2 + p3\n",
    "    return p1 / total, p2 / total, p3 / total\n",
    "\n",
    "p1 = 0.00 # random\n",
    "p2 = 0.20 # heuristic\n",
    "# p3 = 0.10 # stable solution \n",
    "p3 = 0.80 # stable solution \n",
    "ignore_sticks = True\n",
    "MAX_RADIUS = 0.2\n",
    "RADIUS_SCALE = 5.0\n",
    "\n",
    "fps = 5\n",
    "STRIDE = int(100 / fps) #keep  STRIDE=20\n",
    "MAX_SIMULATION_STEPS=1000 # max_frames=50, max duration=10 seconds\n",
    "\n",
    "# Normalize probabilities\n",
    "p1, p2, p3 = normalize_probabilities(p1, p2, p3)\n",
    "\n",
    "def generate_action(featurized_objects, num_balls, is_valid_action, num_sampled_actions=1, eps=0.01,):\n",
    "    \"\"\"\n",
    "    Generate a valid action based on the specified probabilities and methods.\n",
    "    \n",
    "    Parameters:\n",
    "    - featurized_objects: np.ndarray, the initial states of scene objects.\n",
    "    - p1, p2, p3: floats, probabilities for each action generation method.\n",
    "    - candidate_actions: list of actions (np.ndarray) to sample from.\n",
    "    - num_balls: int, number of user balls (1 or 2).\n",
    "    - is_valid_action: function, checks if the generated action is valid.\n",
    "    - eps: float, a small epsilon value to ensure a gap between the object and the scene's upper bound.\n",
    "    \n",
    "    Returns:\n",
    "    - action: np.ndarray, the generated valid action.\n",
    "    \"\"\"\n",
    "    action_dim = 3 * num_balls\n",
    "    filtered_object_id = []\n",
    "    min_radius, max_radius = 1.0, 0\n",
    "    for i in range(featurized_objects.shape[1]):\n",
    "        if featurized_objects[0, i, 4] == 1:\n",
    "            cur_radius = featurized_objects[0, i, 3]/2\n",
    "            min_radius = min(min_radius, cur_radius/2)\n",
    "            max_radius = max(max_radius, cur_radius*4.0)\n",
    "        if ignore_sticks and featurized_objects[0, i, 5] == 1: # bar\n",
    "            continue\n",
    "        filtered_object_id.append(i)\n",
    "    max_radius = min(max_radius, 1.0/RADIUS_SCALE)\n",
    "    \n",
    "    sampled_actions = []\n",
    "    \n",
    "    while True:\n",
    "        # Choose the method based on normalized probabilities\n",
    "        choice = np.random.choice(['random', 'positioning', 'candidate'], p=[p1, p2, p3])\n",
    "        \n",
    "        if choice == 'random':\n",
    "            # Random sample from action space, adjust dimensions for one or two ball tier\n",
    "            action = np.random.rand(action_dim)\n",
    "            action[2] = np.random.uniform(min_radius, max_radius) * RADIUS_SCALE\n",
    "        elif choice == 'positioning': \n",
    "            action = []\n",
    "            for _ in range(num_balls):\n",
    "                # Calculate positioning above another object with constraints\n",
    "                object_idx = random.sample(filtered_object_id, k=1)[0]\n",
    "                # print(object_idx)\n",
    "                object_info = featurized_objects[0, object_idx]  # Including diameter for radius calculation\n",
    "                radius = object_info[3] / 2\n",
    "                my_radius = np.random.uniform(min_radius, max_radius)\n",
    "                max_distubance = radius + my_radius\n",
    "                x_disturbance = np.random.uniform(-0.8 * max_distubance, 0.8 * max_distubance)\n",
    "                y_lower_bound = object_info[1] + x_disturbance * 0.9\n",
    "                y_upper_bound = 1.0 - radius - eps\n",
    "                my_y_pos = np.random.uniform(y_lower_bound, y_upper_bound)\n",
    "                action.extend([object_info[0] + x_disturbance, my_y_pos, my_radius * RADIUS_SCALE])\n",
    "            action = np.array(action)\n",
    "        else:  # 'candidate'\n",
    "            # Sample from the candidate action set, adjusting for one or two balls if necessary\n",
    "            action_idx = np.random.randint(0, len(candidate_solutions))\n",
    "            action = candidate_solutions[action_idx][:action_dim]\n",
    "        \n",
    "        # Check if the action is valid\n",
    "        if is_valid_action(action):\n",
    "            sampled_actions.append(action)\n",
    "            if len(sampled_actions) == num_sampled_actions:\n",
    "                return sampled_actions\n",
    "            \n",
    "\n",
    "def simulate(simulator, task_index, num_trials):\n",
    "    batched_images = []\n",
    "    initial_featurized_objects = simulator.initial_featurized_objects[task_index]\n",
    "    valid_action_check = lambda x: simulator._action_mapper.action_to_user_input(x)[1]\n",
    "    solve_cnt = 0\n",
    "    \n",
    "    # print(initial_featurized_objects.features)\n",
    "    \n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        while True:\n",
    "            \n",
    "            action = generate_action(\n",
    "                initial_featurized_objects.features,\n",
    "                num_balls=int(simulator.action_space_dim/3),\n",
    "                is_valid_action=valid_action_check,\n",
    "                num_sampled_actions=1,\n",
    "            )[0]\n",
    "            \n",
    "            \n",
    "            # Set need_images=False and need_featurized_objects=False to speed up simulation, when only statuses are needed.\n",
    "            # TIME = FRAMES / FPS = k / (STRIDE * FPS)\n",
    "            # print(f'{action}')\n",
    "            simulation = simulator.simulate_action(task_index, action, need_images=True, need_featurized_objects=True\n",
    "                                                   , stride=STRIDE,  max_simulation_steps=MAX_SIMULATION_STEPS)\n",
    "            \n",
    "            if not simulation.status.is_invalid(): \n",
    "                # print(action)\n",
    "\n",
    "                batched_images.append(simulation.images)\n",
    "                if simulation.status.is_solved():\n",
    "                    # print('sovled. Frames is ', len(simulation.images))\n",
    "                    solve_cnt += 1\n",
    "                break\n",
    "            \n",
    "    print(f'Success rate of sampled actions to solve the task: {solve_cnt/num_trials*100:.1f} ({num_trials} trials)')\n",
    "    \n",
    "    return batched_images\n",
    "\n",
    "\n",
    "\n",
    "def sample_and_simulate(simulator, task_index, num_trials, task_name, candidate_solutions, max_loop_per_action=100):\n",
    "    \"\"\"\n",
    "    combine generate_action and simulate to avoid repreated invalid action from generate_action\n",
    "    p1, p2, p3: floats, probabilities for each action generation method.\n",
    "    \"\"\"\n",
    "    batched_images = []\n",
    "    batched_actions = []\n",
    "    batched_final_objects = []\n",
    "    initial_featurized_objects = simulator.initial_featurized_objects[task_index]\n",
    "    featurized_objects = initial_featurized_objects.features\n",
    "    is_valid_action = lambda x: simulator._action_mapper.action_to_user_input(x)[1]\n",
    "    num_balls = int(simulator.action_space_dim/3)\n",
    "    solve_cnt = 0\n",
    "    eps = 0.05\n",
    "    \n",
    "    if candidate_solutions is not None:\n",
    "        new_p1, new_p2, new_p3 = normalize_probabilities(p1, p2, p3)\n",
    "        new_p3 = min(len(candidate_solutions) / num_trials, new_p3)\n",
    "        new_p1 = (1 - new_p3) / (new_p1 + new_p2) * new_p1\n",
    "        new_p2 = (1 - new_p3) / (new_p1 + new_p2) * new_p2\n",
    "        # print(new_p1, new_p2, new_p3)\n",
    "    else:\n",
    "        new_p1, new_p2, new_p3 = normalize_probabilities(p1, p2, 0)\n",
    "    \n",
    "    filtered_object_id = []\n",
    "    min_radius, max_radius = 1.0, 0\n",
    "    for i in range(featurized_objects.shape[1]):\n",
    "        if featurized_objects[0, i, 4] == 1:\n",
    "            cur_radius = featurized_objects[0, i, 3]/2\n",
    "            min_radius = min(min_radius, cur_radius/2)\n",
    "            max_radius = max(max_radius, cur_radius*4.0)\n",
    "        if ignore_sticks and featurized_objects[0, i, 5] == 1 and np.abs(featurized_objects[0, i, 2]) < 0.05: # ignore horizon bar\n",
    "            continue\n",
    "        filtered_object_id.append(i)\n",
    "        \n",
    "    min_radius = max(min_radius, 0.1/RADIUS_SCALE)\n",
    "    max_radius = min(max_radius, 1.0/RADIUS_SCALE)\n",
    "    if len(filtered_object_id) == 0:\n",
    "        filtered_object_id = list(range(featurized_objects.shape[1]))\n",
    "    if min_radius == 1.0 or max_radius == 0:\n",
    "        min_radius = 0.1/RADIUS_SCALE\n",
    "        max_radius = 1.0/RADIUS_SCALE\n",
    "        \n",
    "    random_action_space = None\n",
    "    \n",
    "    # print(initial_featurized_objects.features)\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        loop_cnt = 0\n",
    "        while True:\n",
    "            # if loop_cnt > 0 and loop_cnt % 100 == 0: print(loop_cnt)\n",
    "            # if loop_cnt > 1000: return None, None\n",
    "            # Set need_images=False and need_featurized_objects=False to speed up simulation, when only statuses are needed.\n",
    "            # TIME = FRAMES / FPS = k / (STRIDE * FPS)\n",
    "            # Choose the method based on normalized probabilities\n",
    "            choice = np.random.choice(['random', 'positioning', 'candidate'], p=[new_p1, new_p2, new_p3], )\n",
    "            if loop_cnt < max_loop_per_action:\n",
    "                # heuristic rules\n",
    "                if choice == 'random':\n",
    "                    # Random sample from action space, adjust dimensions for one or two ball tier\n",
    "                    action = np.random.rand(simulator.action_space_dim)\n",
    "                    action[2] = np.random.uniform(min_radius, max_radius) * RADIUS_SCALE\n",
    "                    if simulator.action_space_dim == 6:\n",
    "                        action[5] = np.random.uniform(min_radius, max_radius) * RADIUS_SCALE\n",
    "                elif choice == 'positioning': \n",
    "                    action = []\n",
    "                    for _ in range(num_balls):\n",
    "                        # Calculate positioning above another object with constraints\n",
    "                        object_idx = random.sample(filtered_object_id, k=1)[0]\n",
    "                        # print(object_idx)\n",
    "                        object_info = featurized_objects[0, object_idx]  # Including diameter for radius calculation\n",
    "                        radius = object_info[3] / 2\n",
    "                        my_radius = np.random.uniform(min_radius, max_radius)\n",
    "                        max_distubance = radius + my_radius\n",
    "                        x_disturbance = np.random.uniform(-0.8 * max_distubance, 0.8 * max_distubance)\n",
    "                        if np.random.rand() < 0.5:\n",
    "                            # higher than target object\n",
    "                            y_lower_bound = object_info[1] + x_disturbance * 0.9\n",
    "                            y_upper_bound = 1.0 - radius - eps\n",
    "                        else:\n",
    "                            # lower than target object\n",
    "                            y_lower_bound = radius + eps \n",
    "                            y_upper_bound = object_info[1] - x_disturbance * 0.9\n",
    "                        \n",
    "                        my_y_pos = np.random.uniform(y_lower_bound, y_upper_bound)\n",
    "                        action.extend([object_info[0] + x_disturbance, my_y_pos, my_radius * RADIUS_SCALE])\n",
    "                    action = np.array(action)\n",
    "                else:  # 'candidate'\n",
    "                    action_idx = np.random.randint(0, len(candidate_solutions))\n",
    "                    action = candidate_solutions[action_idx]\n",
    "                    # print(action[2], min_radius * RADIUS_SCALE)\n",
    "                    action[2] = max(action[2], min_radius * RADIUS_SCALE)\n",
    "                if simulator.action_space_dim == 6:\n",
    "                    action[5] = max(action[5], min_radius * RADIUS_SCALE)\n",
    "            else:\n",
    "                # random sample valid actions\n",
    "                print(f'Task {task_name} trial {i} has sampled {loop_cnt} action, yet still has not collected one valid action.') \n",
    "                if random_action_space is None:\n",
    "                    random_action_space = simulator.build_discrete_action_space(max_actions=2*num_trials)       \n",
    "                action = random.choice(random_action_space)\n",
    "                action[2] = np.random.uniform(min_radius, max_radius) * RADIUS_SCALE\n",
    "                if simulator.action_space_dim == 6:\n",
    "                    action[5] = np.random.uniform(min_radius, max_radius) * RADIUS_SCALE\n",
    "                choice = 'valid_random'\n",
    "            \n",
    "            # Check if the action is valid\n",
    "            if is_valid_action(action):\n",
    "                # Set need_images=False and need_featurized_objects=False to speed up simulation, when only statuses are needed.\n",
    "                # TIME = FRAMES / FPS = k / (STRIDE * FPS)\n",
    "                # print(f'{action}')\n",
    "                simulation = simulator.simulate_action(task_index, action, need_images=True, need_featurized_objects=True\n",
    "                                                    , stride=STRIDE,  max_simulation_steps=MAX_SIMULATION_STEPS)\n",
    "                \n",
    "                if not simulation.status.is_invalid(): \n",
    "                    print(task_name, choice, action)\n",
    "                    \n",
    "                    batched_images.append(simulation.images)\n",
    "                    batched_actions.append(action)\n",
    "                    batched_final_objects.append(simulation.featurized_objects.features[-1])\n",
    "                    if simulation.status.is_solved():\n",
    "                        solve_cnt += 1\n",
    "                    break\n",
    "            \n",
    "            # invalid action or invalid status\n",
    "            loop_cnt += 1\n",
    "\n",
    "            \n",
    "    # print(f'Success rate of sampled actions to solve the task: {solve_cnt/num_trials*100:.1f} ({num_trials} trials)')\n",
    "    \n",
    "    # log for diversity analysis\n",
    "    batched_actions = np.stack(batched_actions, 0)\n",
    "    batched_final_objects = np.stack(batched_final_objects, 0)\n",
    "    # print(batched_actions.shape, batched_final_objects.shape)\n",
    "    states = {\n",
    "        'initial_objects': featurized_objects,\n",
    "        'actions': batched_actions,\n",
    "        'final_objects_list': batched_final_objects,\n",
    "    }\n",
    "    \n",
    "    return batched_images, states\n",
    "\n",
    "\n",
    "\n",
    "def analyze_diversity(task_name, states=None, ignore_sticks=True):\n",
    "    actions = states['actions']\n",
    "    # Convert the numpy arrays to pandas DataFrames\n",
    "    df_actions = pd.DataFrame(actions, columns=[f'action {i+1}' for i in range(actions.shape[1])])\n",
    "\n",
    "\n",
    "    # Create subplots\n",
    "    fig_actions = px.parallel_coordinates(df_actions,\n",
    "                                      labels={'Action 1': 'Action 1', \n",
    "                                              'Action 2': 'Action 2', \n",
    "                                              'Action 3': 'Action 3'},\n",
    "                                      color_continuous_scale=px.colors.diverging.Tealrose)\n",
    "    fig_actions.update_layout(title_text=f'{task_name} actions')\n",
    "    # For Actions Plot - Adjusting range for each dimension\n",
    "    for dimension in fig_actions.data[0]['dimensions']:\n",
    "        dimension['range'] = [0, 1]\n",
    "    fig_actions.write_image(f\"vis/{task_name}_actions.png\")\n",
    "    # fig_actions.show()\n",
    "    \n",
    "    if 'final_objects_list' in states:\n",
    "        # initial_state = states['initial_objects']\n",
    "        states = states['final_objects_list']\n",
    "        if ignore_sticks:\n",
    "            object_indices = (states[0, :, 5] == 0) & ((states[0, :, 4] == 0) | (states[0, :, -1] == 0))\n",
    "            states = states[:, object_indices]\n",
    "        states = states[:, :, :3].mean(-1) # compress x, y, angle to a scalar\n",
    "        df_states = pd.DataFrame(states, columns=[f'object {i+1}' for i in range(states.shape[1])])\n",
    "        fig_states = px.parallel_coordinates(df_states, \n",
    "                                     labels={f'State {i}': f'State {i}' for i in range(1, states.shape[1] + 1)},\n",
    "                                     color_continuous_scale=px.colors.diverging.Tealrose)\n",
    "        fig_states.update_layout(title_text=f'{task_name} states')\n",
    "        # For States Plot - Adjusting range for each dimension\n",
    "        for dimension in fig_states.data[0]['dimensions']:\n",
    "            dimension['range'] = [0, 1]\n",
    "        fig_states.write_image(f\"vis/{task_name}_states.png\")\n",
    "        # fig_states.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier = 'ball'\n",
    "cache = phyre.get_default_100k_cache(tier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_actions_dict = {}\n",
    "for task_id, tier in zip(all_tasks_list, all_tiers):\n",
    "    if tier != 'ball': \n",
    "        success_actions_dict[task_id] = None\n",
    "        continue\n",
    "    # print('Randomly selected task:', task_id)\n",
    "    statuses = cache.load_simulation_states(task_id)\n",
    "    success_actions = cache.action_array[statuses == phyre.SimulationStatus.SOLVED]\n",
    "    success_actions_dict[task_id] = success_actions\n",
    "    # if success_actions.shape[0] < 10:\n",
    "    #     print(task_id)\n",
    "    # print(success_actions.shape)\n",
    "    # analyze_diversity(task_id, {'actions': success_actions})\n",
    "    \n",
    "success_actions_counts = np.array([x.shape[0] for x in success_actions_dict.values() if x is not None])\n",
    "# print(success_actions_counts.min(), success_actions_counts.max(), success_actions_counts.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000:000\n",
      "00000:000\n",
      "00001:000\n",
      "00001:000\n",
      "00002:007\n",
      "00002:007\n",
      "00003:000\n",
      "00003:000\n",
      "00004:063\n",
      "00004:063\n",
      "00005:006\n",
      "00005:006\n",
      "00006:003\n",
      "00006:003\n",
      "00007:008\n",
      "00007:008\n",
      "00008:029\n",
      "00008:029\n",
      "00009:013\n",
      "00009:013\n",
      "00010:025\n",
      "00010:025\n",
      "00011:004\n",
      "00011:004\n",
      "00012:002\n",
      "00012:002\n",
      "00013:011\n",
      "00013:011\n",
      "00014:006\n",
      "00014:006\n",
      "00015:014\n",
      "00015:014\n",
      "00016:010\n",
      "00016:010\n",
      "00017:002\n",
      "00017:002\n",
      "00018:007\n",
      "00018:007\n",
      "00019:013\n",
      "00019:013\n",
      "00020:000\n",
      "00020:000\n",
      "00021:002\n",
      "00021:002\n",
      "00022:004\n",
      "00022:004\n",
      "00023:008\n",
      "00023:008\n",
      "00024:006\n",
      "00024:006\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vis all templates\n",
    "tasks = sorted([f'{template}:{instances[0]}' for template, instances in template_dict.items()])[:25]\n",
    "# print(tasks)\n",
    "\n",
    "\n",
    "for i, task_name in enumerate(tasks):\n",
    "    # print(task_name)\n",
    "    simulator =  phyre.initialize_simulator([task_name], 'ball')\n",
    "    batched_imgs, states = sample_and_simulate(simulator, 0, 1, task_name, success_actions_dict[task_name])\n",
    "    print(task_name)\n",
    "    plt.imshow(batched_imgs[0][0])\n",
    "    for j in range(1):\n",
    "        fpath = f'vis/{task_name}_t{j+1}.mp4'\n",
    "        phyre.vis.save_mp4(batched_imgs[j], fps, fpath)\n",
    "    \n",
    "    # phyre.vis.save_observation_series_to_gif_with_space(batched_imgs,fpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00023:008', '00023:017', '00023:031', '00023:064', '00023:111', '00023:112', '00023:134', '00023:153', '00023:202', '00023:223', '00023:233', '00023:240', '00023:241', '00023:245', '00023:261', '00023:269', '00023:310', '00023:316', '00023:320', '00023:377', '00023:385', '00023:402', '00023:428', '00023:438', '00023:441', '00023:470', '00023:471', '00023:490', '00023:493', '00023:506', '00023:507', '00023:513', '00023:522', '00023:523', '00023:534', '00023:535', '00023:538', '00023:543', '00023:566', '00023:584', '00023:614', '00023:625', '00023:636', '00023:644', '00023:655', '00023:666', '00023:680', '00023:689', '00023:704', '00023:728', '00023:736', '00023:740', '00023:745', '00023:751', '00023:754', '00023:757', '00023:767', '00023:771', '00023:778', '00023:797', '00023:800', '00023:801', '00023:812', '00023:817', '00023:818', '00023:819', '00023:820', '00023:821', '00023:829', '00023:839', '00023:848', '00023:850', '00023:857', '00023:859', '00023:873', '00023:875', '00023:878', '00023:879', '00023:883', '00023:884', '00023:898', '00023:899', '00023:901', '00023:913', '00023:918', '00023:925', '00023:926', '00023:930', '00023:936', '00023:946', '00023:948', '00023:950', '00023:952', '00023:957', '00023:959', '00023:960', '00023:963', '00023:972', '00023:974', '00023:990']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:008 candidate [0.38901913 0.7778012  0.5632764 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:017 candidate [0.40026534 0.8227047  0.74613243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:031 positioning [0.91836856 0.76646062 0.25555444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:064 positioning [0.25123    0.78772907 0.52215558]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:09,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:111 positioning [0.70179038 0.20417323 0.42393133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:112 candidate [0.22923195 0.7031352  0.8193327 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:13,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:134 candidate [0.30511308 0.65025043 0.9182987 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:153 candidate [0.3756044 0.7020086 0.865477 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:16,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:202 candidate [0.3495429  0.76838666 0.79133564]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:223 candidate [0.41942084 0.8404545  0.9313939 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:20,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:233 candidate [0.49038863 0.86968446 0.91695625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:22,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:240 candidate [0.40159157 0.6910663  0.5820799 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:24,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:241 candidate [0.34724447 0.48988333 0.9748197 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:26,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:245 candidate [0.3865978  0.87784374 0.7159416 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:261 candidate [0.2642852  0.7272157  0.83728576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:30,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:269 candidate [0.3314645  0.83742714 0.5334453 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:32,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:310 candidate [0.37261236 0.6343075  0.8023289 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:34,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:316 candidate [0.3201439  0.7244477  0.88512415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:36,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:320 candidate [0.38539857 0.66997737 0.5834373 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:37,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:377 candidate [0.30969846 0.9335184  0.5272242 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:40,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:385 candidate [0.35526052 0.531867   0.9807499 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:42,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:402 candidate [0.34208903 0.4773649  0.9970231 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:44,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:428 candidate [0.26983762 0.7152293  0.95710653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:46,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:438 candidate [0.34199035 0.7817078  0.6367916 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:48,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:441 candidate [0.23567012 0.72693133 0.96630734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:470 candidate [0.25079164 0.65038675 0.8932627 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:51,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:471 candidate [0.2924971  0.61856985 0.8429222 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:53,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023:490 candidate [0.21666656 0.78626966 0.74751323]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# vis all instances in a template\n",
    "template = '00023'\n",
    "tasks = sorted([f'{template}:{instance}' for instance in template_dict[template]])\n",
    "print(tasks)\n",
    "\n",
    "batched_videos = []\n",
    "for i, task_name in  tqdm(enumerate(tasks)):\n",
    "    # print(task_name)\n",
    "    simulator =  phyre.initialize_simulator([task_name], 'ball')\n",
    "    batched_imgs, states = sample_and_simulate(simulator, 0, 1, task_name, success_actions_dict[task_name])\n",
    "    batched_videos.append(batched_imgs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(50, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:05<00:00,  5.88s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(batched_videos))\n",
    "print(batched_videos[0].shape)\n",
    "for j in tqdm(range(len(batched_videos)//10+1)):\n",
    "    fpath = f'vis/{template}_t{j*10}-{(j+1)*10}.gif'\n",
    "    phyre.vis.save_observation_series_to_gif_with_space(batched_videos[j*10:(j+1)*10], fpath)\n",
    "\n",
    "    # phyre.vis.save_observation_series_to_gif_with_space(batched_imgs,fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demo_tasks = 30\n",
    "num_trials = 3\n",
    "for eval_setup in all_tasks_dict:\n",
    "    task_setup = all_tasks_dict[eval_setup]\n",
    "    action_tier = task_setup['action_tier']\n",
    "    if action_tier != 'ball': continue\n",
    "    task_indices = sorted(random.sample(range(len(task_setup['tasks'])), k=num_demo_tasks))\n",
    "    print(task_indices)\n",
    "    for i, task_index in enumerate(task_indices):\n",
    "        task_name = task_setup['tasks'][task_index]\n",
    "        simulator =  phyre.initialize_simulator([task_name], action_tier)\n",
    "        batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, success_actions_dict[task_name])\n",
    "        # batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, None)\n",
    "        if batched_imgs is None: continue\n",
    "        # batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, None)\n",
    "        # analyze_diversity(task_name, states)\n",
    "        # TODO: convert to RGB\n",
    "        for j in range(num_trials):\n",
    "            fpath = f'vis/{task_name}_t{j+1}.mp4'\n",
    "            phyre.vis.save_mp4(batched_imgs[j], fps, fpath)\n",
    "        \n",
    "        # phyre.vis.save_observation_series_to_gif_with_space(batched_imgs,fpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165, 302, 388, 404, 412, 570, 572, 601, 894, 1026, 1060, 1154, 1242, 1270, 1352, 1449, 1466, 1577, 1658, 1722, 1778, 1933, 1952, 1990, 2067, 2094, 2181, 2292, 2389, 2465]\n",
      "00102:065 positioning [0.62068209 0.78279532 0.72750365 0.70163359 0.17865962 0.12875222]\n",
      "00102:065 positioning [0.5988884  0.1181126  0.75866521 0.73641244 0.28126965 0.63533885]\n",
      "00102:065 positioning [0.44687722 0.30200998 0.24353101 0.68728124 0.23599528 0.74841089]\n",
      "00107:002 positioning [0.26008781 0.12631872 0.30600928 0.48594887 0.24243643 0.41313409]\n",
      "00107:002 positioning [0.43255542 0.20731431 0.22450044 0.35596579 0.73511356 0.55324256]\n",
      "00107:002 positioning [0.44652371 0.84796946 0.40732128 0.41961438 0.2496851  0.74177481]\n",
      "00107:088 positioning [0.5459241  0.81116682 0.64472868 0.50727793 0.21381896 0.19733991]\n",
      "00107:088 positioning [0.4796306  0.21919121 0.65830806 0.27501402 0.50947102 0.7856138 ]\n",
      "00107:088 positioning [0.48227917 0.77655262 0.44763502 0.43269443 0.15036681 0.90927379]\n",
      "00108:014 positioning [0.38470715 0.87478741 0.28835294 0.51532599 0.79889849 0.33424368]\n",
      "00108:014 positioning [0.54437787 0.23348023 0.43435732 0.35371518 0.85402038 0.474612  ]\n",
      "00108:014 positioning [0.91338229 0.60856243 0.23430312 0.91825946 0.40703376 0.54632259]\n",
      "00108:054 positioning [0.93405815 0.81233292 0.43354555 0.88018262 0.38895187 0.10831547]\n",
      "00108:054 positioning [0.84463284 0.83194485 0.49492767 0.7440853  0.3281337  0.12518261]\n",
      "00108:054 positioning [0.78042124 0.13387401 0.56317805 0.91955665 0.44952527 0.34465407]\n",
      "00111:132 positioning [0.31631673 0.87560415 0.44574678 0.3083477  0.69192938 0.17323859]\n",
      "00111:132 positioning [0.22916082 0.73949736 0.30117733 0.81359881 0.30895137 0.48047509]\n",
      "00111:132 positioning [0.54227351 0.28990531 0.40197658 0.83472311 0.40890092 0.19707058]\n",
      "00111:134 positioning [0.84630709 0.60345659 0.3953737  0.5776843  0.35385089 0.21763666]\n",
      "00111:134 positioning [0.86805737 0.48740992 0.82272864 0.92685124 0.2473288  0.55459273]\n",
      "00111:134 positioning [0.6832955  0.30170214 0.28795374 0.51099042 0.58499864 0.60389164]\n",
      "00112:001 positioning [0.42686219 0.73012768 0.23271121 0.29865809 0.55377351 0.32841314]\n",
      "00112:001 positioning [0.34533651 0.44472588 0.91591927 0.21272505 0.85700462 0.8865606 ]\n",
      "00112:001 positioning [0.10374236 0.28755322 0.71325307 0.17935581 0.08545468 0.14565837]\n",
      "00114:320 positioning [0.44943504 0.26552678 0.33433013 0.34593906 0.75992288 0.98266569]\n",
      "00114:320 positioning [0.06773644 0.16722908 0.13244672 0.18316854 0.43232483 0.28401224]\n",
      "00114:320 positioning [0.23474255 0.54605922 0.38104734 0.40894829 0.8332487  0.51719631]\n",
      "00116:026 positioning [0.56492187 0.37342126 0.56750833 0.22097415 0.29981779 0.12994061]\n",
      "00116:026 positioning [0.2506782  0.70324726 0.32562313 0.64138054 0.15089313 0.3554567 ]\n",
      "00116:026 positioning [0.30273246 0.46912269 0.42616432 0.67942786 0.78777686 0.21434394]\n",
      "00116:061 positioning [0.37308945 0.09022169 0.269618   0.83080816 0.79589789 0.14975883]\n",
      "00116:061 positioning [0.48992788 0.53097338 0.17009227 0.53766617 0.6290114  0.16456576]\n",
      "00116:061 positioning [0.617771   0.85453498 0.15671686 0.76728168 0.8091999  0.33822758]\n",
      "00117:127 positioning [0.20277343 0.20971251 0.15614019 0.51135107 0.55906292 0.36914609]\n",
      "00117:127 positioning [0.17900969 0.311704   0.7506287  0.41240994 0.23989229 0.19294749]\n",
      "00117:127 positioning [0.30845168 0.1558138  0.265407   0.32258218 0.64848694 0.7297075 ]\n",
      "00118:042 positioning [0.68873049 0.53666614 0.12116079 0.04319385 0.26080266 0.25791414]\n",
      "00118:042 positioning [0.11258035 0.52985018 0.39411433 0.0831899  0.36249591 0.54608507]\n",
      "00118:042 positioning [0.25674949 0.29869867 0.16788246 0.95032653 0.66670511 0.13820317]\n",
      "00118:070 positioning [0.54076234 0.68190354 0.1761773  0.23729649 0.34409897 0.5019893 ]\n",
      "00118:070 positioning [0.51039691 0.55365053 0.41580282 0.02752603 0.17286345 0.11195364]\n",
      "00118:070 positioning [0.45278175 0.1087837  0.35177016 0.14545662 0.3079097  0.25389023]\n",
      "00119:126 positioning [0.04404969 0.87681161 0.1765015  0.86457916 0.47610573 0.19819831]\n",
      "00119:126 positioning [0.61617205 0.20861778 0.68358641 0.17968214 0.40420389 0.72556515]\n",
      "00119:126 positioning [0.06684926 0.17301043 0.13014714 0.82571061 0.62255177 0.64255198]\n",
      "00123:203 positioning [0.33318483 0.26325305 0.43494206 0.60626047 0.18029825 0.72560198]\n",
      "00123:203 positioning [0.30474614 0.73900659 0.38310322 0.21885619 0.32831533 0.45037846]\n",
      "00123:203 positioning [0.85502117 0.24296848 0.7336289  0.46316995 0.19188731 0.18500077]\n",
      "00123:237 positioning [0.5177071  0.67047845 0.67579417 0.52126752 0.909167   0.2236953 ]\n",
      "00123:237 positioning [0.79074503 0.208311   0.84722562 0.38927171 0.82058711 0.4975186 ]\n",
      "00123:237 positioning [0.61919469 0.17835917 0.62619364 0.57312637 0.70967895 0.87675179]\n",
      "00124:232 positioning [0.12867445 0.89080767 0.16347527 0.28141084 0.86338967 0.23691489]\n",
      "00124:232 positioning [0.16058263 0.05989521 0.11421798 0.32453417 0.05958565 0.10985422]\n",
      "00124:232 positioning [0.05766643 0.37170575 0.1810328  0.15586875 0.08935997 0.1096057 ]\n",
      "00105:066 positioning [0.88907996 0.57566314 0.57663243 0.29518802 0.56938948 0.51599237]\n",
      "00105:066 positioning [0.72228602 0.631544   0.57468318 0.63498339 0.40905391 0.72497894]\n",
      "00105:066 positioning [0.64224081 0.21458024 0.15790077 0.6835321  0.37691172 0.18478024]\n",
      "00110:022 positioning [0.44794077 0.20309921 0.18406759 0.31606192 0.24736607 0.63414068]\n",
      "00110:022 positioning [0.76243985 0.38153488 0.39186052 0.56053212 0.73870426 0.45456045]\n",
      "00110:022 positioning [0.32645153 0.34232964 0.7368807  0.7361783  0.89248818 0.5332061 ]\n",
      "00110:078 positioning [0.64165251 0.20965664 0.51598977 0.66617611 0.67605659 0.73436891]\n",
      "00110:078 positioning [0.58568762 0.36593171 0.51966392 0.81749742 0.23419678 0.91884734]\n",
      "00110:078 positioning [0.12545321 0.23901326 0.6823816  0.41104923 0.3967589  0.8876187 ]\n",
      "00121:104 positioning [0.200755   0.53388984 0.35495603 0.13529623 0.86984455 0.32577999]\n",
      "00121:104 positioning [0.85109103 0.7630563  0.87186218 0.25297694 0.81955697 0.4093303 ]\n",
      "00121:104 positioning [0.81114981 0.44820764 0.5103389  0.25029017 0.67807636 0.59015361]\n",
      "00121:140 positioning [0.15055902 0.51934358 0.2062817  0.76056793 0.26808581 0.48101472]\n",
      "00121:140 positioning [0.70863165 0.64013051 0.27608686 0.24189619 0.82806767 0.14979956]\n",
      "00121:140 positioning [0.65007528 0.68158432 0.69838399 0.65916708 0.39680574 0.25808594]\n",
      "00121:202 positioning [0.81483211 0.27612443 0.62655994 0.33412586 0.24077684 0.30075106]\n",
      "00121:202 positioning [0.80894675 0.31618839 0.61129164 0.19643945 0.48832798 0.13240098]\n",
      "00121:202 positioning [0.87367102 0.15408871 0.29551397 0.82526292 0.2832587  0.25641541]\n",
      "00101:067 positioning [0.29601802 0.26030519 0.19123504 0.80748515 0.77845063 0.93820069]\n",
      "00101:067 positioning [0.87837005 0.16660543 0.87265763 0.63467524 0.88828419 0.87146388]\n",
      "00101:067 positioning [0.53618398 0.79557576 0.6153101  0.38361278 0.54223604 0.97856462]\n",
      "00101:094 positioning [0.78789113 0.22653815 0.52135673 0.41643844 0.39995394 0.20200763]\n",
      "00101:094 positioning [0.44422174 0.24529574 0.67310349 0.89570097 0.10003733 0.14775978]\n",
      "00101:094 positioning [0.10302791 0.42923619 0.74440109 0.91093936 0.29431552 0.25538481]\n",
      "00103:306 positioning [0.21684365 0.70923816 0.26576103 0.14917886 0.27168661 0.17939134]\n",
      "00103:306 positioning [0.07230851 0.10887215 0.49311553 0.6166402  0.52260034 0.32840945]\n",
      "00103:306 positioning [0.54771044 0.10092902 0.17353721 0.66500435 0.45625278 0.79694045]\n",
      "00106:092 positioning [0.32774359 0.23661686 0.28585315 0.7202048  0.29696577 0.4676419 ]\n",
      "00106:092 positioning [0.65863116 0.21175678 0.59331866 0.68704205 0.84338127 0.28097096]\n",
      "00106:092 positioning [0.78975418 0.50707779 0.1346743  0.26966031 0.13678965 0.59679697]\n",
      "00109:151 positioning [0.42167336 0.91030309 0.39521981 0.35941901 0.68382845 0.27418786]\n",
      "00109:151 positioning [0.57533462 0.59069789 0.15541783 0.44560027 0.63210632 0.25779119]\n",
      "00109:151 positioning [0.35427422 0.5786647  0.18941391 0.54776455 0.77540133 0.3176731 ]\n",
      "00122:238 positioning [0.32482026 0.54814752 0.66720111 0.51475218 0.73568978 0.12955282]\n",
      "00122:238 positioning [0.37791606 0.27673965 0.15038469 0.60572234 0.68639733 0.19827344]\n",
      "00122:238 positioning [0.34616712 0.63251468 0.3787099  0.88481092 0.24082869 0.30401658]\n"
     ]
    }
   ],
   "source": [
    "num_demo_tasks = 30\n",
    "num_trials = 3\n",
    "for eval_setup in all_tasks_dict:\n",
    "    task_setup = all_tasks_dict[eval_setup]\n",
    "    action_tier = task_setup['action_tier']\n",
    "    if action_tier == 'ball': continue\n",
    "    task_indices = sorted(random.sample(range(len(task_setup['tasks'])), k=num_demo_tasks))\n",
    "    print(task_indices)\n",
    "    for i, task_index in enumerate(task_indices):\n",
    "        task_name = task_setup['tasks'][task_index]\n",
    "        simulator =  phyre.initialize_simulator([task_name], action_tier)\n",
    "        batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, success_actions_dict[task_name])\n",
    "        # batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, None)\n",
    "        if batched_imgs is None: continue\n",
    "        # batched_imgs, states = sample_and_simulate(simulator, 0, num_trials, task_name, None)\n",
    "        # analyze_diversity(task_name, states)\n",
    "        # TODO: convert to RGB\n",
    "        for j in range(num_trials):\n",
    "            fpath = f'vis/{task_name}_t{j+1}.mp4'\n",
    "            phyre.vis.save_mp4(batched_imgs[j], fps, fpath)\n",
    "        \n",
    "        # phyre.vis.save_observation_series_to_gif_with_space(batched_imgs,fpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index (1000) out of range for (0-999)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 148\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frames, action\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# store_frames_to_hdf5(batched_imgs[-1], fps, 'videos.hdf5')\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# start_time = time.time()\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# frames, _ = decode_hdf5_to_frames('../phyre_data_1000_v2/00001:005.hdf5', 90)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# print(\"decode_hdf5_to_frames: Finished in {:.2f} seconds\".format(time.time() - start_time))\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# start_time = time.time()\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m frames, action \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_hdf5_to_frames_wo_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../phyre_data_1000_v3/00001:006.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# print(\"decode_hdf5_to_frames_wo_disk: Finished in {:.2f} seconds\".format(time.time() - start_time))\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# print(frames.shape, frames2.shape)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# frames == frames\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 133\u001b[0m, in \u001b[0;36mdecode_hdf5_to_frames_wo_disk\u001b[0;34m(hdf5_path, trial_index, format_hint)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode video frames from a byte stream stored in an HDF5 file directly in memory.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m hdf \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(hdf5_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m byte_stream \u001b[38;5;241m=\u001b[39m \u001b[43mhdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo_streams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrial_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    134\u001b[0m byte_obj \u001b[38;5;241m=\u001b[39m byte_stream\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Decode frames directly from byte stream\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/dataset.py:831\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# === Everything else ===================\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# Perform the dataspace selection.\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m selection \u001b[38;5;241m=\u001b[39m \u001b[43msel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selection\u001b[38;5;241m.\u001b[39mnselect \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mzeros(selection\u001b[38;5;241m.\u001b[39marray_shape, dtype\u001b[38;5;241m=\u001b[39mnew_dtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/selections.py:82\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(shape, args, dataset)\u001b[0m\n\u001b[1;32m     79\u001b[0m     space \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape)\n\u001b[1;32m     80\u001b[0m     selector \u001b[38;5;241m=\u001b[39m _selector\u001b[38;5;241m.\u001b[39mSelector(space)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_selector.pyx:282\u001b[0m, in \u001b[0;36mh5py._selector.Selector.make_selection\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_selector.pyx:151\u001b[0m, in \u001b[0;36mh5py._selector.Selector.apply_args\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Index (1000) out of range for (0-999)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import imageio\n",
    "import tempfile\n",
    "import imageio.v3 as iio # need python at least 3.9\n",
    "from pathlib import Path\n",
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "def read_file_to_byte_stream(file_path):\n",
    "    \"\"\"Read the entire content of a file into a byte stream.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        byte_stream = file.read()\n",
    "    return byte_stream\n",
    "\n",
    "\n",
    "def store_byte_stream_to_hdf5(byte_stream, hdf5_path, dataset_name):\n",
    "    \"\"\"Store a byte stream in an HDF5 file as a dataset.\"\"\"\n",
    "    data = np.frombuffer(byte_stream, dtype=np.uint8)\n",
    "    \n",
    "    with h5py.File(hdf5_path, 'w') as hdf:\n",
    "        hdf.create_dataset(dataset_name, data=data, dtype='uint8')\n",
    "\n",
    "\n",
    "def convert_frames_to_mp4_bytestream(frames, fps=5):\n",
    "    \"\"\"\n",
    "    Convert a sequence of frames into an MP4 byte stream.\n",
    "\n",
    "    Parameters:\n",
    "    - frames: A list or array of frames (numpy arrays).\n",
    "    - fps: Frames per second for the output video.\n",
    "\n",
    "    Returns:\n",
    "    - A byte stream of the MP4 video.\n",
    "    \"\"\"\n",
    "    # Use a temporary file to store the video\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:\n",
    "        temp_file_name = temp_file.name      \n",
    "        imageio.mimsave(temp_file_name, frames, fps=fps)\n",
    "\n",
    "        # Read the MP4 file content into a byte stream\n",
    "        with open(temp_file_name, 'rb') as video_file:\n",
    "            mp4_bytestream = video_file.read()\n",
    "    stream_array = np.frombuffer(mp4_bytestream, dtype='uint8')\n",
    "    return stream_array\n",
    "\n",
    "\n",
    "\n",
    "def convert_frames_to_mp4_bytestream_wo_disk(frames, fps=5):\n",
    "    \"\"\"\n",
    "    Convert a sequence of frames into an MP4 byte stream, entirely in-memory.\n",
    "    \n",
    "    Parameters:\n",
    "    - frames: A list or array of frames (numpy arrays).\n",
    "    - fps: Frames per second for the output video.\n",
    "    \n",
    "    Returns:\n",
    "    - A byte stream of the MP4 video.\n",
    "    \"\"\"\n",
    "    # Create an in-memory bytes buffer\n",
    "    with BytesIO() as buffer:\n",
    "        # Use imageio to write frames to the buffer as an MP4 video\n",
    "        iio.imwrite(buffer, frames, extension='.mp4')\n",
    "        \n",
    "        # Get the byte stream from the buffer\n",
    "        mp4_bytestream = buffer.getvalue()\n",
    "    \n",
    "    return np.frombuffer(mp4_bytestream, dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def store_mp4_to_hdf5(mp4_path, hdf5_path):\n",
    "    stream = read_file_to_byte_stream(mp4_path)\n",
    "    store_byte_stream_to_hdf5(stream, hdf5_path, dataset_name='task1')\n",
    "    \n",
    "    \n",
    "def store_batched_frames_to_hdf5(all_frames, hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'w') as hdf:\n",
    "        video_dset =hdf.create_dataset('video_streams', \n",
    "                           shape=(len(all_frames),),\n",
    "                           dtype=h5py.vlen_dtype(np.dtype('uint8')),\n",
    "                           )   \n",
    "        \n",
    "        batch_size = 100\n",
    "        for i in range(0, len(all_frames), batch_size):\n",
    "            batched_frames = all_frames[i:i+batch_size]\n",
    "            # speedup time bottleneck by parallelizing batch\n",
    "            # start_time_step = time.time()\n",
    "            batched_images = phyre.vis.batched_observations_to_frames(batched_frames)\n",
    "            # batched_images = np.stack(batched_images, 0)\n",
    "            # batched_images = WAD_COLORS[batched_images]\n",
    "            # print(f\"Time for obs2frames\", time.time() - start_time_step, \"seconds\")\n",
    "            \n",
    "            for j, images in enumerate(batched_images):\n",
    "                start_time_step = time.time()\n",
    "                # writing to disk is faster than in-memory operation\n",
    "                stream = convert_frames_to_mp4_bytestream(images) # time bottleneck\n",
    "                # stream = convert_frames_to_mp4_bytestream_wo_disk(images) # time bottleneck\n",
    "                print(f\"Time for frames2bytestream\", time.time() - start_time_step, \"seconds\")\n",
    "                \n",
    "                trial_id = i + j\n",
    "                video_dset[trial_id] = stream\n",
    "\n",
    "    \n",
    "    return\n",
    "        \n",
    "    \n",
    "def decode_hdf5_to_frames(hdf5_path, trial_index):\n",
    "    \"\"\"Decode video frames from a byte stream stored in an HDF5 file by first writing to a temporary file.\"\"\"\n",
    "        \n",
    "    hdf = h5py.File(hdf5_path, 'r')\n",
    "        \n",
    "    byte_stream = hdf['video_streams'][trial_index]\n",
    "    byte_obj = byte_stream.tobytes()\n",
    "    # Use a temporary file to write the byte stream\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:\n",
    "        temp_file_name = temp_file.name\n",
    "        temp_file.write(byte_obj)\n",
    "    \n",
    "    # Now read the video from the temporary file\n",
    "    with imageio.get_reader(temp_file_name, format='mp4') as reader:\n",
    "        frames = [frame for frame in reader]\n",
    "        fps = reader.get_meta_data()['fps']\n",
    "    \n",
    "    imageio.mimsave('deocded_v1.mp4', frames, fps=5)\n",
    "    \n",
    "    return np.array(frames), fps\n",
    "    \n",
    "def decode_hdf5_to_frames_wo_disk(hdf5_path, trial_index, format_hint='.mp4'):\n",
    "    \"\"\"Decode video frames from a byte stream stored in an HDF5 file directly in memory.\"\"\"\n",
    "    hdf = h5py.File(hdf5_path, 'r')\n",
    "\n",
    "    byte_stream = hdf['video_streams'][trial_index]\n",
    "    byte_obj = byte_stream.tobytes()\n",
    "    # Decode frames directly from byte stream\n",
    "    frames = iio.imread(byte_obj, index=None, extension=format_hint)\n",
    "    imageio.mimsave('deocded_v2.mp4', frames, fps=5)\n",
    "    action = hdf['action_streams'][trial_index]\n",
    "    return frames, action\n",
    "\n",
    "    \n",
    "# store_frames_to_hdf5(batched_imgs[-1], fps, 'videos.hdf5')\n",
    "# start_time = time.time()\n",
    "# frames, _ = decode_hdf5_to_frames('../phyre_data_1000_v2/00001:005.hdf5', 90)\n",
    "# print(\"decode_hdf5_to_frames: Finished in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# start_time = time.time()\n",
    "frames, action = decode_hdf5_to_frames_wo_disk('../phyre_data_1000_v3/00001:006.hdf5', 1000)\n",
    "print(action)\n",
    "# print(\"decode_hdf5_to_frames_wo_disk: Finished in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# print(frames.shape, frames2.shape)\n",
    "# frames == frames\n",
    "\n",
    "frames2 = frames\n",
    "# print(frames2.shape, frames2.dtype)\n",
    "\n",
    "# it seems imageio in python3.9 is 2x faster than python3.6\n",
    "# start_time = time.time()\n",
    "# s1 = convert_frames_to_mp4_bytestream(frames2, fps=5)\n",
    "# print(\"Finished in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# start_time = time.time()\n",
    "# s2 = convert_frames_to_mp4_bytestream_wo_disk(frames2, fps=5)\n",
    "# print(\"Finished in {:.2f} seconds\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imageio_ffmpeg\n",
    "\n",
    "def gif_to_mp4(gif_path, output_path, fps=10):\n",
    "    \"\"\"\n",
    "    Convert a GIF to an MP4 video using imageio.\n",
    "\n",
    "    Parameters:\n",
    "    - gif_path: Path to the input GIF file.\n",
    "    - output_path: Path where the output MP4 file will be saved.\n",
    "    - fps: Frames per second for the output video.\n",
    "    \"\"\"\n",
    "    # Read GIF\n",
    "    reader = imageio.get_reader(gif_path)\n",
    "    \n",
    "    # Get GIF metadata\n",
    "    meta_data = reader.get_meta_data()\n",
    "    \n",
    "    # Define MP4 writer with desired fps\n",
    "    writer = imageio.get_writer(output_path, fps=fps, codec='libx264', quality=7)\n",
    "\n",
    "    # Iterate over GIF frames and add them to the MP4 writer\n",
    "    for frame in reader:\n",
    "        writer.append_data(frame)\n",
    "    \n",
    "    # Close writer and reader to free up resources\n",
    "    writer.close()\n",
    "    reader.close()\n",
    "\n",
    "# Example usage\n",
    "gif_path = 'vis/00120:099.gif'  # Replace with your GIF file path\n",
    "output_path = 'vis/00120:099.mp4'  # Replace with your desired output MP4 file path\n",
    "gif_to_mp4(gif_path, output_path, fps=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_videos_hdf5(tasks, action_tier, num_trials=100, data_dir='./'):\n",
    "    # Start measuring time for step 1\n",
    "    start_time_step1 = time.time()\n",
    "    \n",
    "    # Step 1: initialize simulator\n",
    "    simulator = phyre.initialize_simulator(tasks, action_tier)\n",
    "    # End measuring time for step 1 and print duration\n",
    "    print(\"Time for Step 1 (initialize simulator):\", time.time() - start_time_step1, \"seconds\")\n",
    "    \n",
    "    for task_index, task_name in enumerate(tasks):\n",
    "        # Start measuring time for step 2\n",
    "        start_time_step2 = time.time()\n",
    "        \n",
    "        # Step 2: simulate K trials\n",
    "        batched_imgs = simulate(simulator, task_index, num_trials)\n",
    "        # End measuring time for step 2 and print duration\n",
    "        print(f\"Time for Step 2 (simulate {num_trials} trials) for task\", task_name, \":\", time.time() - start_time_step2, \"seconds\")\n",
    "        \n",
    "        # Start measuring time for step 3\n",
    "        start_time_step3 = time.time()\n",
    "        \n",
    "        # Step 3: save all trials' videos\n",
    "        hdf5_path = Path(data_dir) / f'{task_name}.hdf5'\n",
    "        store_batched_frames_to_hdf5(batched_imgs, hdf5_path)\n",
    "        # End measuring time for step 3 and print duration\n",
    "        print(\"Time for Step 3 (save all trials' videos) for task\", task_name, \":\", time.time() - start_time_step3, \"seconds\")\n",
    "        \n",
    "# eval_setup = 'ball_cross_template'\n",
    "# train_tasks, dev_tasks, test_tasks = phyre.get_fold(eval_setup, 0)\n",
    "# action_tier = phyre.eval_setup_to_action_tier(eval_setup)\n",
    "# tasks = train_tasks[:1]\n",
    "# print(tasks, action_tier)\n",
    "# generate_videos_hdf5(tasks, action_tier, num_trials=100)"
   ]
  }
 ],
 "metadata": {
  "fileId": "fcbb17f1-d1b4-4b8e-ba5f-d0201169b281",
  "jupytext": {
   "formats": "ipynb,py:light",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,-kernelspec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit ('phyre')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c190783f89b15ec4aa6ef5b841b841f0cb5ee9eb2933860efc05a8dd747911ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
